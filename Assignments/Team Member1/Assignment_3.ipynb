{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### DataSet Loading"
      ],
      "metadata": {
        "id": "D1ECVEXtGmnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1WjaeBb5EnDp"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8V38AxmFnY5",
        "outputId": "8266c368-3909-41ed-a9ff-1612419fd235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4322 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "x_train=train_datagen.flow_from_directory('/content/drive/MyDrive/flowers/Flowers-Dataset/flowers',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwC6JOi1Z_24",
        "outputId": "73a0b4ff-be23-4b17-d15d-44fc9dc23393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4322 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "x_test=test_datagen.flow_from_directory('/content/drive/MyDrive/flowers/Flowers-Dataset/flowers',target_size=(64,64),batch_size=300,class_mode='categorical',color_mode='grayscale')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation & adding layers"
      ],
      "metadata": {
        "id": "vTwD2M83GwGh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Vls0JozLB3WW"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j4ASiKT-CUwB"
      },
      "outputs": [],
      "source": [
        "model= Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3nLGnCj-CeET"
      },
      "outputs": [],
      "source": [
        "model.add(Convolution2D(32,(3,3),input_shape=(64,64,1),activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "smpaGFhWCymW"
      },
      "outputs": [],
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KDEkIyYEDCV8"
      },
      "outputs": [],
      "source": [
        "model.add(Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ed-IFm__DJK8"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=512,activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U8909ib1DV4g"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units=9,activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXbVU1abC_NK"
      },
      "source": [
        "### Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "kK-eH5uLDdf0"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving model"
      ],
      "metadata": {
        "id": "P4ZH6IfNH2PO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1aJBq4vEAxa",
        "outputId": "3a467a95-86fe-4cbc-99e5-b1bc701546d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=24,epochs=10,validation_data=x_test,validation_steps=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8oSKbvaiaZhb"
      },
      "outputs": [],
      "source": [
        "model.save('aslpng1.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Testing"
      ],
      "metadata": {
        "id": "K5sqcM1FHkHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "metadata": {
        "id": "NRg-Lg-ndWss"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=load_model('/content/aslpng1.h5')"
      ],
      "metadata": {
        "id": "6ehQVmK9daFH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "def detect(frame):\n",
        "  img = resize(frame,(64,64,1))\n",
        "  img = np.expand_dims(img,axis=0)\n",
        "  if(np.max(img)>1):\n",
        "    img=img/255.0\n",
        "  prediction = model.predict(img)\n",
        "  print(prediction)\n",
        "  predictions = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        " \n",
        "  print(prediction)\n"
      ],
      "metadata": {
        "id": "oHwvjfGidwni"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame = cv2.imread(r\"/content/drive/MyDrive/flowers/Flowers-Dataset/flowers/sunflower/1008566138_6927679c8a.jpg\")\n",
        "data = detect(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0UvlVYYefwY",
        "outputId": "4a0b22c9-49ea-4f89-a4c7-f68dd716f02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1347757  0.1006939  0.09727424 0.1056136  0.11490836 0.11649807\n",
            "  0.11035961 0.12321131 0.09666524]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}